{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT_Q&A Task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQxF95ynpTg6"
      },
      "source": [
        "# BERT_Q&A Task\n",
        "\n",
        "A deep neural language model (BERT) and fine-tuned it to deal with the task of Q&A with PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY7mmcj9pRcW",
        "outputId": "7a49649a-6b1c-476e-d074-333599f5f87e"
      },
      "source": [
        "# verify GPU availability\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yxu0iAvYsHTK",
        "outputId": "b39182f9-744d-47ce-d9f5-2b83c855fc2d"
      },
      "source": [
        "# install huggingface libraries\n",
        "!pip install pytorch-pretrained-bert pytorch-nlp pytorch_transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: pytorch_transformers in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.9.0+cu102)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.18.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (0.1.96)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (0.0.45)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.5.0)\n",
            "Requirement already satisfied: botocore<1.22.0,>=1.21.10 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.21.10)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.10->boto3->pytorch-pretrained-bert) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.10->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.10->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "x9ANT1FssMH4",
        "outputId": "36f91933-c4c6-48ed-92d0-6e23968dd3e0"
      },
      "source": [
        "# BERT imports\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from pytorch_pretrained_bert import BertForQuestionAnswering\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# specify GPU device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hkii9bEqsRDJ",
        "outputId": "26e0f1df-8ae0-46ce-d545-286038cf3d09"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DwYBV-2askA",
        "outputId": "b9621201-0604-4256-d6b8-b04f93776ccc"
      },
      "source": [
        "!ls /drive/My\\ Drive/squad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7_17\t\t  checkpoint-1000  checkpoint-final\t   predictions.json\n",
            "7_19\t\t  checkpoint-2000  dev-v2.0.json\t   train-v2.0.json\n",
            "cache_train\t  checkpoint-3000  nbest_predictions.json\n",
            "cache_validation  checkpoint-4000  null_odds.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnOX9wfQngPf"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/drive/My Drive/squad/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yxjlwseeykl",
        "outputId": "7a5dae0b-7503-44de-d4cf-3b730f563792"
      },
      "source": [
        "!wget 'https://raw.githubusercontent.com/nlpyang/pytorch-transformers/master/examples/utils_squad.py'\n",
        "!wget 'https://raw.githubusercontent.com/nlpyang/pytorch-transformers/master/examples/utils_squad_evaluate.py'\n",
        "\n",
        "from utils_squad import (read_squad_examples, convert_examples_to_features,\n",
        "                         RawResult, write_predictions,\n",
        "                         RawResultExtended, write_predictions_extended)\n",
        "from utils_squad_evaluate import EVAL_OPTS, main as evaluate_on_squad, plot_pr_curve"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-30 02:41:25--  https://raw.githubusercontent.com/nlpyang/pytorch-transformers/master/examples/utils_squad.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41529 (41K) [text/plain]\n",
            "Saving to: ‘utils_squad.py.2’\n",
            "\n",
            "\rutils_squad.py.2      0%[                    ]       0  --.-KB/s               \rutils_squad.py.2    100%[===================>]  40.56K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2021-07-30 02:41:25 (11.7 MB/s) - ‘utils_squad.py.2’ saved [41529/41529]\n",
            "\n",
            "--2021-07-30 02:41:25--  https://raw.githubusercontent.com/nlpyang/pytorch-transformers/master/examples/utils_squad_evaluate.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12493 (12K) [text/plain]\n",
            "Saving to: ‘utils_squad_evaluate.py.2’\n",
            "\n",
            "utils_squad_evaluat 100%[===================>]  12.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-07-30 02:41:25 (52.6 MB/s) - ‘utils_squad_evaluate.py.2’ saved [12493/12493]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGVWI85yfaPs",
        "outputId": "ef5887e5-f90f-490f-a210-9292f547fcf7"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHgpndcloLFp"
      },
      "source": [
        "input_file = '/drive/My Drive/squad/train-v2.0.json'\n",
        "examples = read_squad_examples(input_file=input_file,\n",
        "                                is_training=True,\n",
        "                                version_2_with_negative=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVeg2Gw2mJYc",
        "outputId": "9f0821f8-e688-41e7-92dd-e13ed52201ca"
      },
      "source": [
        "examples[:5]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[qas_id: 56be85543aeaaa14008c9063, question_text: When did Beyonce start becoming popular?, doc_tokens: [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".], start_position: 39, end_position: 42,\n",
              " qas_id: 56be85543aeaaa14008c9065, question_text: What areas did Beyonce compete in when she was growing up?, doc_tokens: [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".], start_position: 28, end_position: 30,\n",
              " qas_id: 56be85543aeaaa14008c9066, question_text: When did Beyonce leave Destiny's Child and become a solo singer?, doc_tokens: [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".], start_position: 82, end_position: 82,\n",
              " qas_id: 56bf6b0f3aeaaa14008c9601, question_text: In what city and state did Beyonce  grow up? , doc_tokens: [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".], start_position: 22, end_position: 23,\n",
              " qas_id: 56bf6b0f3aeaaa14008c9602, question_text: In which decade did Beyonce become famous?, doc_tokens: [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".], start_position: 41, end_position: 42]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "TWRV-Q10qrIM",
        "outputId": "4d4dcb6e-6e32-4247-82e4-a6f4cd8b1709"
      },
      "source": [
        "train_data = pd.DataFrame.from_records([vars(example) for example in examples])\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qas_id</th>\n",
              "      <th>question_text</th>\n",
              "      <th>doc_tokens</th>\n",
              "      <th>orig_answer_text</th>\n",
              "      <th>start_position</th>\n",
              "      <th>end_position</th>\n",
              "      <th>is_impossible</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56be85543aeaaa14008c9063</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>[Beyoncé, Giselle, Knowles-Carter, (/biːˈjɒnse...</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>39</td>\n",
              "      <td>42</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56be85543aeaaa14008c9065</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>[Beyoncé, Giselle, Knowles-Carter, (/biːˈjɒnse...</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>28</td>\n",
              "      <td>30</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56be85543aeaaa14008c9066</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>[Beyoncé, Giselle, Knowles-Carter, (/biːˈjɒnse...</td>\n",
              "      <td>2003</td>\n",
              "      <td>82</td>\n",
              "      <td>82</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
              "      <td>In what city and state did Beyonce  grow up?</td>\n",
              "      <td>[Beyoncé, Giselle, Knowles-Carter, (/biːˈjɒnse...</td>\n",
              "      <td>Houston, Texas</td>\n",
              "      <td>22</td>\n",
              "      <td>23</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
              "      <td>In which decade did Beyonce become famous?</td>\n",
              "      <td>[Beyoncé, Giselle, Knowles-Carter, (/biːˈjɒnse...</td>\n",
              "      <td>late 1990s</td>\n",
              "      <td>41</td>\n",
              "      <td>42</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     qas_id  ... is_impossible\n",
              "0  56be85543aeaaa14008c9063  ...         False\n",
              "1  56be85543aeaaa14008c9065  ...         False\n",
              "2  56be85543aeaaa14008c9066  ...         False\n",
              "3  56bf6b0f3aeaaa14008c9601  ...         False\n",
              "4  56bf6b0f3aeaaa14008c9602  ...         False\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "cNVta-8TrNN8",
        "outputId": "f5a7fbfc-ac8d-411b-d4ec-41c6f9be7ccb"
      },
      "source": [
        "sample = train_data.sample(frac=1).head(1)\n",
        "context = sample.doc_tokens.values\n",
        "train_data[train_data.doc_tokens.values==context]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qas_id</th>\n",
              "      <th>question_text</th>\n",
              "      <th>doc_tokens</th>\n",
              "      <th>orig_answer_text</th>\n",
              "      <th>start_position</th>\n",
              "      <th>end_position</th>\n",
              "      <th>is_impossible</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>103678</th>\n",
              "      <td>572f498104bcaa1900d76817</td>\n",
              "      <td>What was a disadvantage of DC system?</td>\n",
              "      <td>[An, early, advantage, of, AC, is, that, the, ...</td>\n",
              "      <td>power-wasting resistors</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103679</th>\n",
              "      <td>572f498104bcaa1900d76818</td>\n",
              "      <td>How can different range of voltages be supplie...</td>\n",
              "      <td>[An, early, advantage, of, AC, is, that, the, ...</td>\n",
              "      <td>multiple taps on the transformer</td>\n",
              "      <td>24</td>\n",
              "      <td>28</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103680</th>\n",
              "      <td>572f498104bcaa1900d76819</td>\n",
              "      <td>What taps can provide lighting supply?</td>\n",
              "      <td>[An, early, advantage, of, AC, is, that, the, ...</td>\n",
              "      <td>low-voltage transformer windings</td>\n",
              "      <td>36</td>\n",
              "      <td>38</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103681</th>\n",
              "      <td>572f498104bcaa1900d7681a</td>\n",
              "      <td>What will AC/DC motor be replaced with?</td>\n",
              "      <td>[An, early, advantage, of, AC, is, that, the, ...</td>\n",
              "      <td>three-phase induction motor</td>\n",
              "      <td>69</td>\n",
              "      <td>71</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103682</th>\n",
              "      <td>572f498104bcaa1900d7681b</td>\n",
              "      <td>What is the main advantage of an induction motor?</td>\n",
              "      <td>[An, early, advantage, of, AC, is, that, the, ...</td>\n",
              "      <td>can run equally well on DC or AC of any frequency</td>\n",
              "      <td>93</td>\n",
              "      <td>103</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103683</th>\n",
              "      <td>5acd7ee207355d001abf4476</td>\n",
              "      <td>What was an early disadvantage of AC?</td>\n",
              "      <td>[An, early, advantage, of, AC, is, that, the, ...</td>\n",
              "      <td></td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103684</th>\n",
              "      <td>5acd7ee207355d001abf4477</td>\n",
              "      <td>One taps on the transformer can supply what?</td>\n",
              "      <td>[An, early, advantage, of, AC, is, that, the, ...</td>\n",
              "      <td></td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103685</th>\n",
              "      <td>5acd7ee207355d001abf4478</td>\n",
              "      <td>The development of low power semiconductors ca...</td>\n",
              "      <td>[An, early, advantage, of, AC, is, that, the, ...</td>\n",
              "      <td></td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103686</th>\n",
              "      <td>5acd7ee207355d001abf4479</td>\n",
              "      <td>No modern electric locomotives are designed to...</td>\n",
              "      <td>[An, early, advantage, of, AC, is, that, the, ...</td>\n",
              "      <td></td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103687</th>\n",
              "      <td>5acd7ee207355d001abf447a</td>\n",
              "      <td>Combined low-voltage transformer windings supp...</td>\n",
              "      <td>[An, early, advantage, of, AC, is, that, the, ...</td>\n",
              "      <td></td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          qas_id  ... is_impossible\n",
              "103678  572f498104bcaa1900d76817  ...         False\n",
              "103679  572f498104bcaa1900d76818  ...         False\n",
              "103680  572f498104bcaa1900d76819  ...         False\n",
              "103681  572f498104bcaa1900d7681a  ...         False\n",
              "103682  572f498104bcaa1900d7681b  ...         False\n",
              "103683  5acd7ee207355d001abf4476  ...          True\n",
              "103684  5acd7ee207355d001abf4477  ...          True\n",
              "103685  5acd7ee207355d001abf4478  ...          True\n",
              "103686  5acd7ee207355d001abf4479  ...          True\n",
              "103687  5acd7ee207355d001abf447a  ...          True\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX4yzlpmuSkQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86ObEyQtkqjs"
      },
      "source": [
        "import random\n",
        "def print_squad_sample(train_data, line_length=14, separator_length=120):\n",
        "  sample = train_data.sample(frac=1).head(1)\n",
        "  context = sample.doc_tokens.values\n",
        "  print('='*separator_length)\n",
        "  print('CONTEXT: ')\n",
        "  print('='*separator_length)\n",
        "  lines = [' '.join(context[0][idx:idx+line_length]) for idx in range(0, len(context[0]), line_length)]\n",
        "  for l in lines:\n",
        "      print(l)\n",
        "  print('='*separator_length)\n",
        "  questions = train_data[train_data.doc_tokens.values==context]\n",
        "  print('QUESTION:', ' '*(3*separator_length//4), 'ANSWER:')\n",
        "  for idx, row in questions.iterrows():\n",
        "    question = row.question_text\n",
        "    answer = row.orig_answer_text\n",
        "    print(question, ' '*(3*separator_length//4-len(question)+9), (answer if answer else 'No awnser found'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU4S6x0YnnPT",
        "outputId": "e66117e4-ae35-486b-e9b4-213adbdc0b2a"
      },
      "source": [
        "print_squad_sample(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========================================================================================================================\n",
            "CONTEXT: \n",
            "========================================================================================================================\n",
            "Italian unification was the political and social movement that annexed different states of the\n",
            "Italian peninsula into the single state of Italy in the 19th century. There is\n",
            "a lack of consensus on the exact dates for the beginning and the end\n",
            "of this period, but many scholars agree that the process began with the end\n",
            "of Napoleonic rule and the Congress of Vienna in 1815, and approximately ended with\n",
            "the Franco-Prussian War in 1871, though the last città irredente did not join the\n",
            "Kingdom of Italy until after World War I.\n",
            "========================================================================================================================\n",
            "QUESTION:                                                                                            ANSWER:\n",
            "What is Italian Unification?                                                                         social movement that annexed different states of the Italian peninsula into the single state of Italy\n",
            "When did the Italian Unification occur?                                                              in the 19th century\n",
            "In what year do most  Scholars agree the Italian Unification began?                                  1815\n",
            "In what year do most  Scholars agree the Italian Unification ended?                                  1871\n",
            "After what event did the last citta irredente join Italy?                                            World War I.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbnphaodvb_u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "H3yDIGj8t1_M",
        "outputId": "ba42ccb8-aa2f-406d-e679-b15dcd85616a"
      },
      "source": [
        "\n",
        "train_data['paragraph_len'] = train_data['doc_tokens'].apply(len)\n",
        "train_data['question_len'] = train_data['question_text'].apply(len)\n",
        "train_data.sample(frac=1).head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qas_id</th>\n",
              "      <th>question_text</th>\n",
              "      <th>doc_tokens</th>\n",
              "      <th>orig_answer_text</th>\n",
              "      <th>start_position</th>\n",
              "      <th>end_position</th>\n",
              "      <th>is_impossible</th>\n",
              "      <th>paragraph_len</th>\n",
              "      <th>question_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>108606</th>\n",
              "      <td>5a2d5fa3f28ef0001a526506</td>\n",
              "      <td>Where is the headquarters for the League of Am...</td>\n",
              "      <td>[Santa, Monica, has, a, bike, action, plan, an...</td>\n",
              "      <td></td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>True</td>\n",
              "      <td>86</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107689</th>\n",
              "      <td>572f425b04bcaa1900d767ea</td>\n",
              "      <td>How are antennas oriented when arranged with s...</td>\n",
              "      <td>[For, instance,, a, phased, array, consists, o...</td>\n",
              "      <td>parallel</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>False</td>\n",
              "      <td>98</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65085</th>\n",
              "      <td>5acfce2e77cf76001a6860d4</td>\n",
              "      <td>How many works displayed at The Salon de la Se...</td>\n",
              "      <td>[The, Section, d'Or,, also, known, as, Groupe,...</td>\n",
              "      <td></td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>True</td>\n",
              "      <td>115</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130017</th>\n",
              "      <td>5735ca406c16ec1900b927df</td>\n",
              "      <td>What type of religion is Kirant Mundhum?</td>\n",
              "      <td>[Kirant, Mundhum, is, one, of, the, indigenous...</td>\n",
              "      <td>animistic</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>False</td>\n",
              "      <td>84</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2182</th>\n",
              "      <td>5a8d914edf8bba001a0f9b0b</td>\n",
              "      <td>Through what can Link's verbalizations be disc...</td>\n",
              "      <td>[There, is, very, little, voice, acting, in, t...</td>\n",
              "      <td></td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>True</td>\n",
              "      <td>99</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          qas_id  ... question_len\n",
              "108606  5a2d5fa3f28ef0001a526506  ...           64\n",
              "107689  572f425b04bcaa1900d767ea  ...           62\n",
              "65085   5acfce2e77cf76001a6860d4  ...          105\n",
              "130017  5735ca406c16ec1900b927df  ...           40\n",
              "2182    5a8d914edf8bba001a0f9b0b  ...           52\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VduHO4WoXwp",
        "outputId": "93a4509c-3aef-4f6c-c935-57916c189dad"
      },
      "source": [
        "max_seq_length = 256\n",
        "print(\"Percentage of context's less than max_seq_length = %s%%\" % (len([l for l in train_data['paragraph_len'] if l <= max_seq_length])/len(train_data) * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of context's less than max_seq_length = 98.19289589392184%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zywEw_BZtx5l"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Dj9SoVnuSh2"
      },
      "source": [
        "doc_stride = 128\n",
        "max_seq_length = 256\n",
        "max_query_length = 64\n",
        "# batch size of 64 if RAM available.\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS2oM0q3pdni"
      },
      "source": [
        "cached_features_file = '/drive/My Drive/squad/cache_train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxXiC4G2uUwa"
      },
      "source": [
        "if not os.path.exists(cached_features_file):\n",
        "  features = convert_examples_to_features(examples=examples,\n",
        "                                        tokenizer=tokenizer,\n",
        "                                        max_seq_length=max_seq_length,\n",
        "                                        doc_stride=doc_stride,\n",
        "                                        max_query_length=max_query_length,\n",
        "                                        is_training=True)\n",
        "  torch.save(features, cached_features_file)\n",
        "else:\n",
        "  features = torch.load(cached_features_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqKRwvvjuW1I"
      },
      "source": [
        "def set_seed(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8wpGNktunPQ"
      },
      "source": [
        "# Convert to Tensors and build dataset\n",
        "all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
        "all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
        "all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
        "all_cls_index = torch.tensor([f.cls_index for f in features], dtype=torch.long)\n",
        "all_p_mask = torch.tensor([f.p_mask for f in features], dtype=torch.float)\n",
        "\n",
        "all_start_positions = torch.tensor([f.start_position for f in features], dtype=torch.long)\n",
        "all_end_positions = torch.tensor([f.end_position for f in features], dtype=torch.long)\n",
        "dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n",
        "                        all_start_positions, all_end_positions,\n",
        "                        all_cls_index, all_p_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siznTVwRuvkC"
      },
      "source": [
        "train_sampler = RandomSampler(dataset)\n",
        "train_dataloader = DataLoader(dataset, sampler=train_sampler, batch_size=batch_size, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfJGpCMcu01s"
      },
      "source": [
        "import glob\n",
        "checkpoints = sorted(glob.glob('/drive/My Drive/squad/checkpoint*-[0-9]*'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE-mmGhwIJWe"
      },
      "source": [
        "def to_list(tensor):\n",
        "    return tensor.detach().cpu().tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d06HFmPmu3Yq",
        "outputId": "105ee1c3-9df1-4d5a-9493-c9aa96d36249"
      },
      "source": [
        "if len(checkpoints) > 0:\n",
        "  global_step = checkpoints[-1].split('-')[-1]\n",
        "  ckpt_name = '/drive/My Drive/squad/checkpoint-{}'.format(global_step)\n",
        "  print(\"Loading model from checkpoint %s\" % ckpt_name)\n",
        "  model = BertForQuestionAnswering.from_pretrained(ckpt_name)\n",
        "  train_loss_set_ckpt = torch.load(ckpt_name + '/training_loss.pt')\n",
        "  train_loss_set = to_list(train_loss_set_ckpt)\n",
        "  tr_loss = train_loss_set[-1]\n",
        "else:\n",
        "  global_step = 0\n",
        "  train_loss_set = []\n",
        "  tr_loss = 0.0\n",
        "  model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model from checkpoint /drive/My Drive/squad/checkpoint-4000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForQuestionAnswering(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t19YTyEu5V4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46fcd18c-1ed7-4a90-8c4f-b516c0ed7183"
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "print(param_optimizer[-2])\n",
        "print(param_optimizer[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('qa_outputs.weight', Parameter containing:\n",
            "tensor([[-0.0070,  0.0070, -0.0011,  ...,  0.0011,  0.0258,  0.0148],\n",
            "        [-0.0079,  0.0184, -0.0486,  ...,  0.0001,  0.0208, -0.0173]],\n",
            "       device='cuda:0', requires_grad=True))\n",
            "('qa_outputs.bias', Parameter containing:\n",
            "tensor([0.0051, 0.0057], device='cuda:0', requires_grad=True))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9alnEO5Uu7jm"
      },
      "source": [
        "learning_rate = 3e-5\n",
        "adam_epsilon=1e-8\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGwiPd3ju9A1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        },
        "outputId": "71aad95b-c347-45a5-a865-86a8f795230f"
      },
      "source": [
        "num_train_epochs = 3\n",
        "\n",
        "print(\"***** Running training *****\")\n",
        "print(\"  Num examples = %d\" % len(dataset))\n",
        "print(\"  Num Epochs = %d\" % num_train_epochs)\n",
        "print(\"  Batch size = %d\" % batch_size)\n",
        "print(\"  Total optimization steps = %d\" % (len(train_dataloader) // num_train_epochs))\n",
        "\n",
        "model.zero_grad()\n",
        "train_iterator = trange(num_train_epochs, desc=\"Epoch\")\n",
        "set_seed()\n",
        "\n",
        "for _ in train_iterator:\n",
        "    epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
        "    for step, batch in enumerate(epoch_iterator):\n",
        "      if step < int(global_step) + 1:\n",
        "        continue\n",
        "\n",
        "      model.train()\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "      inputs = {'input_ids':       batch[0],\n",
        "                'attention_mask':  batch[1], \n",
        "                'token_type_ids':  batch[2],  \n",
        "                'start_positions': batch[3], \n",
        "                'end_positions':   batch[4]}\n",
        "\n",
        "      outputs = model(**inputs)\n",
        "\n",
        "      loss = outputs[0]\n",
        "      train_loss_set.append(loss)\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "      tr_loss += loss.item()\n",
        "      optimizer.step()\n",
        "      model.zero_grad()\n",
        "      global_step = int(global_step)\n",
        "      global_step += 1\n",
        "    \n",
        "      if global_step % 1000 == 0:\n",
        "        print(\"Train loss: {}\".format(tr_loss/global_step))\n",
        "        output_dir = '/drive/My Drive/squad/checkpoint-{}'.format(global_step)\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "        model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "        model_to_save.save_pretrained(output_dir)\n",
        "        torch.save(torch.tensor(train_loss_set), os.path.join(output_dir, 'training_loss.pt'))\n",
        "        print(\"Saving model checkpoint to %s\" % output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Iteration:   0%|          | 0/4508 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 144262\n",
            "  Num Epochs = 3\n",
            "  Batch size = 32\n",
            "  Total optimization steps = 1502\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration:   1%|▏         | 58/4508 [00:00<00:13, 329.53it/s]\u001b[A\n",
            "Iteration:   4%|▍         | 182/4508 [00:00<00:10, 422.43it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 312/4508 [00:00<00:07, 529.65it/s]\u001b[A\n",
            "Iteration:  10%|▉         | 440/4508 [00:00<00:06, 641.63it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 563/4508 [00:00<00:05, 748.00it/s]\u001b[A\n",
            "Iteration:  15%|█▌        | 692/4508 [00:00<00:04, 855.46it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 829/4508 [00:00<00:03, 964.07it/s]\u001b[A\n",
            "Iteration:  21%|██▏       | 969/4508 [00:00<00:03, 1062.58it/s]\u001b[A\n",
            "Iteration:  25%|██▍       | 1107/4508 [00:00<00:02, 1141.31it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 1244/4508 [00:01<00:02, 1201.46it/s]\u001b[A\n",
            "Iteration:  31%|███       | 1375/4508 [00:01<00:02, 1215.34it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 1504/4508 [00:01<00:02, 1224.92it/s]\u001b[A\n",
            "Iteration:  36%|███▋      | 1636/4508 [00:01<00:02, 1248.38it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 1776/4508 [00:01<00:02, 1287.85it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 1913/4508 [00:01<00:01, 1309.69it/s]\u001b[A\n",
            "Iteration:  45%|████▌     | 2047/4508 [00:01<00:01, 1275.78it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 2179/4508 [00:01<00:01, 1288.55it/s]\u001b[A\n",
            "Iteration:  51%|█████     | 2310/4508 [00:01<00:01, 1272.96it/s]\u001b[A\n",
            "Iteration:  54%|█████▍    | 2445/4508 [00:02<00:01, 1293.67it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 2588/4508 [00:02<00:01, 1330.08it/s]\u001b[A\n",
            "Iteration:  60%|██████    | 2723/4508 [00:02<00:01, 1334.16it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 2857/4508 [00:02<00:01, 1304.80it/s]\u001b[A\n",
            "Iteration:  66%|██████▋   | 2991/4508 [00:02<00:01, 1313.91it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 3123/4508 [00:02<00:01, 1304.24it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 3257/4508 [00:02<00:00, 1313.74it/s]\u001b[A\n",
            "Iteration:  75%|███████▌  | 3389/4508 [00:02<00:00, 1294.95it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 3519/4508 [00:02<00:00, 1293.94it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 3649/4508 [00:02<00:00, 1286.52it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 3782/4508 [00:03<00:00, 1299.12it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 3913/4508 [00:03<00:00, 1288.05it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-114106bfc412>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m       \u001b[0mtrain_loss_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUfeq9kO1oYM"
      },
      "source": [
        "output_dir = '/drive/My Drive/squad/checkpoint-final'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "model_to_save = model.module if hasattr(model, 'module') else model\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "\n",
        "torch.save(torch.tensor(train_loss_set), os.path.join(output_dir, 'training_loss.pt'))\n",
        "print(\"Saving model checkpoint to %s\" % output_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpoznGAgYcWE"
      },
      "source": [
        "# train_loss_set = []\n",
        "# for tmp in ['1000', '2000', '3000', '4000','5000','6000','7000','8000','9000','final']:\n",
        "#   #'10000','11000','12000', '13000','14000','15000','16000','17000','18000',\n",
        "#   train_loss_set_ckpt = torch.load('/drive/My Drive/squad/checkpoint-'+tmp+'/training_loss.pt')\n",
        "#   train_loss_set_ckpt = to_list(train_loss_set_ckpt)\n",
        "#   train_loss_set += train_loss_set_ckpt\n",
        "\n",
        "train_loss_set_ckpt = torch.load('/drive/My Drive/squad/checkpoint-final/training_loss.pt')\n",
        "train_loss_set = to_list(train_loss_set_ckpt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z2GxIeN1vqa"
      },
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_set)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyVaTl1i17jC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b2hzsaq16H6"
      },
      "source": [
        "**Load test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TglKsny312Oh"
      },
      "source": [
        "input_file = '/drive/My Drive/squad/dev-v2.0.json'\n",
        "val_examples = read_squad_examples(input_file=input_file,\n",
        "                                is_training=False,\n",
        "                                version_2_with_negative=True)\n",
        "doc_stride = 128\n",
        "max_seq_length = 256\n",
        "max_query_length = 64\n",
        "cached_features_file = '/drive/My Drive/squad/cache_validation'\n",
        "\n",
        "# Cache features for faster loading\n",
        "if not os.path.exists(cached_features_file):\n",
        "  features = convert_examples_to_features(examples=val_examples,\n",
        "                                        tokenizer=tokenizer,\n",
        "                                        max_seq_length=max_seq_length,\n",
        "                                        doc_stride=doc_stride,\n",
        "                                        max_query_length=max_query_length,\n",
        "                                        is_training=False)\n",
        "  torch.save(features, cached_features_file)\n",
        "else:\n",
        "  features = torch.load(cached_features_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLmoahbz1_Hx"
      },
      "source": [
        "# Convert to Tensors and build dataset\n",
        "all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
        "all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
        "all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
        "all_cls_index = torch.tensor([f.cls_index for f in features], dtype=torch.long)\n",
        "all_p_mask = torch.tensor([f.p_mask for f in features], dtype=torch.float)\n",
        "\n",
        "all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long)\n",
        "dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n",
        "                        all_example_index, all_cls_index, all_p_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMMV4KIh2OKt"
      },
      "source": [
        "validation_sampler = SequentialSampler(dataset)\n",
        "validation_dataloader = DataLoader(dataset, sampler=validation_sampler, batch_size=batch_size, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLdGjs5G2V5O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbrsNDUm2Url"
      },
      "source": [
        "**Evaluate test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3_CAQUf2asD"
      },
      "source": [
        "\n",
        "def evaluate(model, tokenizer):\n",
        "  print(\"***** Running evaluation *****\")\n",
        "  print(\"  Num examples = %d\" % len(dataset))\n",
        "  print(\"  Batch size = %d\" % batch_size)\n",
        "  all_results = []\n",
        "  predict_file = '/drive/My Drive/squad/dev-v2.0.json'\n",
        "  for batch in tqdm(validation_dataloader, desc=\"Evaluating\", miniters=100, mininterval=5.0):\n",
        "    model.eval()\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    with torch.no_grad():\n",
        "      inputs = {'input_ids':      batch[0],\n",
        "                'attention_mask': batch[1],\n",
        "                'token_type_ids': batch[2]\n",
        "                }\n",
        "      example_indices = batch[3]\n",
        "      outputs = model(**inputs)\n",
        "\n",
        "    for i, example_index in enumerate(example_indices):\n",
        "      eval_feature = features[example_index.item()]\n",
        "      unique_id = int(eval_feature.unique_id)\n",
        "\n",
        "      result = RawResult(unique_id    = unique_id,\n",
        "                         start_logits = to_list(outputs[0][i]),\n",
        "                         end_logits   = to_list(outputs[1][i]))\n",
        "      all_results.append(result)\n",
        "\n",
        "  # Compute predictions\n",
        "  output_prediction_file = \"/drive/My Drive/squad/predictions.json\"\n",
        "  output_nbest_file = \"/drive/My Drive/squad/nbest_predictions.json\"\n",
        "  output_null_log_odds_file = \"/drive/My Drive/squad/null_odds.json\"\n",
        "  output_dir = \"/drive/My Drive/squad/predict_results\"\n",
        "\n",
        "  #return all_results\n",
        "\n",
        "  write_predictions(val_examples, features, all_results, 10,\n",
        "                  30, True, output_prediction_file,\n",
        "                  output_nbest_file, output_null_log_odds_file, False,\n",
        "                  True, 0.0)\n",
        "\n",
        "  # Evaluate with the official SQuAD script\n",
        "  evaluate_options = EVAL_OPTS(data_file=predict_file,\n",
        "                               pred_file=output_prediction_file,\n",
        "                               na_prob_file=output_null_log_odds_file,\n",
        "                               out_image_dir=None)\n",
        "  results = evaluate_on_squad(evaluate_options)\n",
        "\n",
        "  print(features)\n",
        "  print(all_results)\n",
        "  return results\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROJlB2Np2iTo"
      },
      "source": [
        "results = evaluate(model, tokenizer)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}